<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Student Pass/Fail AI - Neural Network Visualization</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="main-container">
        <h1>Student Pass/Fail AI</h1>
        <h2>Neural Network from Scratch in NumPy</h2>
        <p class="author">Made by Rohit</p>
        
        <div class="viz-container">
            <svg viewBox="0 0 800 600" xmlns="http://www.w3.org/2000/svg">
                
                <g id="connections-input-hidden">
                    <line class="connection input-1 hidden-1" x1="100" y1="200" x2="350" y2="120"/>
                    <line class="connection input-1 hidden-2" x1="100" y1="200" x2="350" y2="220"/>
                    <line class="connection input-1 hidden-3" x1="100" y1="200" x2="350" y2="320"/>
                    <line class="connection input-1 hidden-4" x1="100" y1="200" x2="350" y2="420"/>
                    
                    <line class="connection input-2 hidden-1" x1="100" y1="400" x2="350" y2="120"/>
                    <line class="connection input-2 hidden-2" x1="100" y1="400" x2="350" y2="220"/>
                    <line class="connection input-2 hidden-3" x1="100" y1="400" x2="350" y2="320"/>
                    <line class="connection input-2 hidden-4" x1="100" y1="400" x2="350" y2="420"/>
                </g>
                
                <g id="connections-hidden-output">
                    <line class="connection hidden-1 output-1" x1="350" y1="120" x2="600" y2="220"/>
                    <line class="connection hidden-1 output-2" x1="350" y1="120" x2="600" y2="380"/>

                    <line class="connection hidden-2 output-1" x1="350" y1="220" x2="600" y2="220"/>
                    <line class="connection hidden-2 output-2" x1="350" y1="220" x2="600" y2="380"/>

                    <line class="connection hidden-3 output-1" x1="350" y1="320" x2="600" y2="220"/>
                    <line class="connection hidden-3 output-2" x1="350" y1="320" x2="600" y2="380"/>

                    <line class="connection hidden-4 output-1" x1="350" y1="420" x2="600" y2="220"/>
                    <line class="connection hidden-4 output-2" x1="350" y1="420" x2="600" y2="380"/>
                </g>
                
                <g id="input-layer">
                    <text class="layer-label" x="100" y="80">Input Layer</text>
                    <text class="label" x="100" y="105">(2 Neurons)</text>
                    
                    <circle class="neuron" id="input-1" cx="100" cy="200" r="30"/>
                    <text class="label" x="100" y="205">Score</text>
                    
                    <circle class="neuron" id="input-2" cx="100" cy="400" r="30"/>
                    <text class="label" x="100" y="405">Study</text>
                    <text class="label" x="100" y="420">Hours</text>
                </g>
                
                <g id="hidden-layer">
                    <text class="layer-label" x="350" y="50">Hidden Layer</text>
                    <text class="label" x="350" y="75">(4 Neurons)</text>
                    
                    <circle class="neuron" id="hidden-1" cx="350" cy="120" r="25"/>
                    <circle class="neuron" id="hidden-2" cx="350" cy="220" r="25"/>
                    <circle class="neuron" id="hidden-3" cx="350" cy="320" r="25"/>
                    <circle class="neuron" id="hidden-4" cx="350" cy="420" r="25"/>
                </g>
                
                <g id="output-layer">
                    <text class="layer-label" x="600" y="80">Output Layer</text>
                    <text class="label" x="600" y="105">(2 Neurons)</text>
                    
                    <circle class="neuron" id="output-1" cx="600" cy="220" r="30"/>
                    <text class="label" x="600" y="225">FAIL</text>
                    
                    <circle class="neuron" id="output-2" cx="600" cy="380" r="30"/>
                    <text class="label" x="600" y="385">PASS</text>
                </g>
                
                <text class="weight-label" x="225" y="240">Weights: 2√ó4</text>
                <text class="weight-label" x="475" y="300">Weights: 4√ó2</text>
            </svg>
        </div>
        
        <div class="info-container">
            <h3>Student Pass/Fail AI (Neural Network from Scratch in NumPy)</h3>
            
            <p>This project is a complete, functional Artificial Intelligence built from the ground up using only <strong>NumPy</strong>. It demonstrates the core mathematics and logic of deep learning without relying on any high-level libraries like TensorFlow or Keras.</p>
            
            <p>The AI is trained to predict whether a student will <strong>"Pass"</strong> or <strong>"Fail"</strong> based on two features: their <strong>Score</strong> and their <strong>Study Hours</strong>.</p>
            
            <h4>Network Architecture (2-4-2)</h4>
            
            <p>This network uses a simple Multi-Layer Perceptron (MLP) architecture with one hidden layer. The flow of information is as follows:</p>
            
            <div class="architecture-diagram">
                <pre>
[Input Layer] (2 Neurons)
     ( )  [Score]
     ( )  [Study Hours]
      |
      |  (Weights: 2√ó4) - Connects 2 input neurons to 4 hidden neurons
      v
[Hidden Layer] (4 Neurons) - Uses Sigmoid Activation
     ( )
     ( )
     ( )
     ( )
      |
      |  (Weights: 4√ó2) - Connects 4 hidden neurons to 2 output neurons
      v
[Output Layer] (2 Neurons) - Uses Softmax Activation
     ( )  [FAIL]
     ( )  [PASS]
                </pre>
            </div>
            
            <h4>Key Components Explained</h4>
            
            <div class="highlight-box">
                <p><strong>üî¢ Weights & Biases:</strong></p>
                <ul>
                    <li><strong>Hidden Weights (2√ó4):</strong> Random values multiplied by 0.01 for small initial learning. Shape (2,4) connects input to hidden layer.</li>
                    <li><strong>Hidden Biases (4,):</strong> One bias per hidden neuron, starting from zero.</li>
                    <li><strong>Output Weights (4√ó2):</strong> Connects 4 hidden neurons to 2 output neurons.</li>
                    <li><strong>Output Biases (2,):</strong> One bias per output neuron, initialized to 0.01.</li>
                </ul>
            </div>
            
            <div class="highlight-box">
                <p><strong>üéØ Activation Functions:</strong></p>
                <ul>
                    <li><strong>Sigmoid:</strong> Squashes values to 0-1 range. Formula: 1 / (1 + e^(-x))</li>
                    <li><strong>Softmax:</strong> Converts output to probabilities that sum to 1. Perfect for classification!</li>
                    <li><strong>Sigmoid Derivative:</strong> Used in backpropagation: x * (1 - x)</li>
                </ul>
            </div>
            
            <h4>Training Process (1000 Epochs)</h4>
            
            <p>Each epoch follows this cycle:</p>
            
            <div class="highlight-box">
                <p><strong>1Ô∏è‚É£ Forward Pass:</strong></p>
                <ul>
                    <li><strong>Input ‚Üí Hidden:</strong> hidden_inputs = (data √ó weights) + bias</li>
                    <li><strong>Apply Sigmoid:</strong> hidden_outputs = sigmoid(hidden_inputs) ‚Üí Values like [0.8, 0.6, 0.9, 0.7]</li>
                    <li><strong>Hidden ‚Üí Output:</strong> output_inputs = (hidden_outputs √ó weights) + bias</li>
                    <li><strong>Apply Softmax:</strong> output_probs = softmax(output_inputs) ‚Üí [0.2, 0.8] (80% PASS, 20% FAIL)</li>
                </ul>
            </div>
            
            <div class="highlight-box">
                <p><strong>2Ô∏è‚É£ Calculate Error (Cross-Entropy Loss):</strong></p>
                <ul>
                    <li>Compare prediction [0.2, 0.8] with truth [0, 1]</li>
                    <li>Error = [0.2, -0.2]</li>
                    <li>Loss = -mean(sum(labels √ó log(predictions)))</li>
                </ul>
            </div>
            
            <div class="highlight-box">
                <p><strong>3Ô∏è‚É£ Backward Pass (Backpropagation):</strong></p>
                <ul>
                    <li><strong>Output Layer:</strong> Calculate error at output neurons</li>
                    <li><strong>Update Output Weights:</strong> weights -= (learning_rate √ó gradient) / num_samples</li>
                    <li><strong>Update Output Biases:</strong> biases -= learning_rate √ó average_error</li>
                    <li><strong>Hidden Layer:</strong> Propagate error back to hidden neurons</li>
                    <li><strong>Update Hidden Weights & Biases:</strong> Same formula as output layer</li>
                </ul>
            </div>
            
            <h4>Hyperparameters</h4>
            
            <div class="highlight-box">
                <ul>
                    <li><strong>Learning Rate: 0.1</strong> - Controls how much weights change in each update (moderate learning speed)</li>
                    <li><strong>Epochs: 1000</strong> - Number of times the entire training data loops through the network</li>
                    <li><strong>Training Data: 5 samples</strong> - Students with scores and study hours</li>
                </ul>
            </div>
            
            <h4>Example Prediction Flow</h4>
            
            <div class="highlight-box">
                <p><strong>Input:</strong> Student with Score=90, Study Hours=20.5</p>
                <p><strong>Step 1:</strong> [90, 20.5] √ó weights + bias ‚Üí hidden_inputs</p>
                <p><strong>Step 2:</strong> sigmoid(hidden_inputs) ‚Üí [0.8, 0.6, 0.9, 0.7]</p>
                <p><strong>Step 3:</strong> [0.8, 0.6, 0.9, 0.7] √ó weights + bias ‚Üí output_inputs</p>
                <p><strong>Step 4:</strong> softmax(output_inputs) ‚Üí [0.2, 0.8]</p>
                <p><strong>Output:</strong> 80% PASS, 20% FAIL ‚Üí <strong>Prediction: PASS</strong> ‚úÖ</p>
            </div>
            
            <h4>Features</h4>
            
            <ul>
                <li><strong>‚úÖ Pure NumPy Implementation:</strong> No TensorFlow or Keras required</li>
                <li><strong>‚úÖ Complete Training Loop:</strong> Forward pass, loss calculation, and backpropagation</li>
                <li><strong>‚úÖ Live Predictions:</strong> Enter new student data and get instant predictions with confidence scores</li>
                <li><strong>‚úÖ Loss Tracking:</strong> Monitor training progress every 200 epochs</li>
                <li><strong>‚úÖ Matrix Operations:</strong> Efficient batch processing using NumPy arrays</li>
            </ul>
        </div>
    </div>
    
    <script src="script.js"></script>
</body>
</html>
